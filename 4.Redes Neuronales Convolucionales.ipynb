{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c2c9dc-822f-43b4-85c5-4ba15664b944",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Convolutional Neural Networks with Keras</font></h1>\n",
    "\n",
    "- En este tutorial, mostraré como usar la libreria Keras para construir una Red Neuronal Convolucional. \n",
    "\n",
    "- También usaremos la popular MNIST dataset y compararemos nuestros resultados con el uso de una red neuronal convencional. \n",
    "\n",
    "---\n",
    "\n",
    "## Red Neuronal Convolucional con Keras\n",
    "\n",
    "### Objetivos para este Notebook\n",
    "<h5> 1. Cómo utilizar la biblioteca de Keras para construir redes neuronales convolucionales.</h5>\n",
    "<h5> 2. Red neuronal convolucional con una capa convolucional y agrupada.</h5>\n",
    "<h5> 3. Red neuronal convolucional con dos capas convolucionales y agrupadas.</h5>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Importando Keras y paquetes\n",
    "\n",
    "Coemnzamos importando la libreria keras y los paquetes que necesitaremos para construir una red Neuronal Convolucional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d051f956-c284-416e-af48-dca228702297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399e91b-3529-4067-9d7d-e50d4f5871bc",
   "metadata": {},
   "source": [
    "- Cuando trabajamos con Redes Neuronales Convolucionales en particular, necesitaremos paquetes adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe84785-fed1-4df1-88e3-610b98436370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv2D   #Agrega capas Convolucionales\n",
    "from keras.layers.convolutional import MaxPooling2D    # Agregar pooling layers\n",
    "from keras.layers import Flatten   #Aplanar los datos para fully connected Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb639b8-a7fc-4ed9-a3a9-da9628aec6e4",
   "metadata": {},
   "source": [
    "## Capa Convolucional con un conjunto de capas convolucional y pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa21de4b-36c3-40fd-ae0f-1ce10c92ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar datos\n",
    "from keras.datasets import mnist\n",
    "\n",
    "#Cargar los datos\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ac31a-fb67-48e0-8411-491396143e84",
   "metadata": {},
   "source": [
    "- Ahora normalizaremos los valores de pixeles para estar entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02abd077-5864-479b-a957-e4b1517a4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255 # normalize training data\n",
    "X_test = X_test / 255 # normalize test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1656f8f-8cb0-4ed3-81e0-0561a264ad0b",
   "metadata": {},
   "source": [
    "- A continuacion, convertimos la variable objetivo o target en categoria binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a924a47-5d87-4b7c-9c29-1a50b89987bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25663e0f-f629-4831-9199-0b052bf86920",
   "metadata": {},
   "source": [
    "- Ahora, definimos una funcion que creara nuestro modelo. Comenzamos con un conjunto de capas convolucionales y pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36ee9739-741a-4de8-ab4e-a1f84678f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4621805-4ba2-49de-9b0c-766e8a1a0375",
   "metadata": {},
   "source": [
    "- Finalmente, llamamos a la funcion para crear el modelo, y luego lo entrenamos y evaluamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be5ac3f-9ed7-4792-9985-bebc54b307b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 64s - loss: 0.2940 - accuracy: 0.9157 - val_loss: 0.1103 - val_accuracy: 0.9664\n",
      "Epoch 2/10\n",
      "300/300 - 57s - loss: 0.0850 - accuracy: 0.9748 - val_loss: 0.0630 - val_accuracy: 0.9800\n",
      "Epoch 3/10\n",
      "300/300 - 58s - loss: 0.0580 - accuracy: 0.9832 - val_loss: 0.0536 - val_accuracy: 0.9834\n",
      "Epoch 4/10\n",
      "300/300 - 57s - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.0440 - val_accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "300/300 - 57s - loss: 0.0375 - accuracy: 0.9883 - val_loss: 0.0401 - val_accuracy: 0.9861\n",
      "Epoch 6/10\n",
      "300/300 - 57s - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0415 - val_accuracy: 0.9846\n",
      "Epoch 7/10\n",
      "300/300 - 58s - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0485 - val_accuracy: 0.9841\n",
      "Epoch 8/10\n",
      "300/300 - 57s - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0406 - val_accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "300/300 - 57s - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0380 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "300/300 - 57s - loss: 0.0142 - accuracy: 0.9958 - val_loss: 0.0398 - val_accuracy: 0.9874\n",
      "Accuracy: 0.9873999953269958 \n",
      " Error: 1.260000467300415\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064808d7-8437-42f0-9727-72682a9c71b9",
   "metadata": {},
   "source": [
    "## Capa Convolucional con 2 conjuntos de capas de convolucion y pooling\n",
    "\n",
    "Redefinamos nuestro modelo convolucional para que tenga dos capas convolucionales y agrupadas en lugar de solo una capa de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7144a65a-0cb6-4ab8-bf12-f21bea97c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafbcca-a868-4644-9789-c7a7ff3a2951",
   "metadata": {},
   "source": [
    "- Ahora, llamamos a la funcion para crear nuestro nueva Red Neuronal Convolucional, y luego lo entrenamos y validamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dedcf3d-b5dd-446b-abc0-909bd0267802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "300/300 - 60s - loss: 0.4656 - accuracy: 0.8671 - val_loss: 0.1347 - val_accuracy: 0.9602\n",
      "Epoch 2/10\n",
      "300/300 - 74s - loss: 0.1115 - accuracy: 0.9665 - val_loss: 0.0850 - val_accuracy: 0.9743\n",
      "Epoch 3/10\n",
      "300/300 - 57s - loss: 0.0790 - accuracy: 0.9759 - val_loss: 0.0659 - val_accuracy: 0.9799\n",
      "Epoch 4/10\n",
      "300/300 - 56s - loss: 0.0638 - accuracy: 0.9805 - val_loss: 0.0506 - val_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "300/300 - 79s - loss: 0.0541 - accuracy: 0.9832 - val_loss: 0.0523 - val_accuracy: 0.9829\n",
      "Epoch 6/10\n",
      "300/300 - 70s - loss: 0.0468 - accuracy: 0.9858 - val_loss: 0.0467 - val_accuracy: 0.9846\n",
      "Epoch 7/10\n",
      "300/300 - 72s - loss: 0.0418 - accuracy: 0.9875 - val_loss: 0.0409 - val_accuracy: 0.9867\n",
      "Epoch 8/10\n",
      "300/300 - 68s - loss: 0.0380 - accuracy: 0.9885 - val_loss: 0.0395 - val_accuracy: 0.9870\n",
      "Epoch 9/10\n",
      "300/300 - 70s - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0461 - val_accuracy: 0.9844\n",
      "Epoch 10/10\n",
      "300/300 - 68s - loss: 0.0329 - accuracy: 0.9896 - val_loss: 0.0378 - val_accuracy: 0.9871\n",
      "Accuracy: 0.9871000051498413 \n",
      " Error: 1.2899994850158691\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac906e1e-b87a-4f38-aabd-99f4db4816d1",
   "metadata": {},
   "source": [
    "Esto concluye este Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025325ab-3b52-42f8-8969-b9a1c36775a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
