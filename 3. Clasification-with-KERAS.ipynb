{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc1392e7-cdf8-452e-8750-1b6674561ff0",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Classification Models with Keras</font></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd670b4-04fb-4cf3-b7bf-32d529c0d99c",
   "metadata": {},
   "source": [
    "## Introduccion\n",
    "\n",
    "- En esta guia, aprenderemos como usar la libreria Keras para construir modelos para problemas de clasificación. Usaremos el popular dataset MNIST, un dataset de imagenes.\n",
    "\n",
    "- La base de datos MNIST, abreviatura de la base de datos Modified National Institute of Standards and Technology, es una gran base de datos de dígitos escritos a mano que se usa comúnmente para entrenar varios sistemas de procesamiento de imágenes. La base de datos también se usa ampliamente para capacitación y pruebas en el campo del aprendizaje automático.\n",
    "\n",
    "- La base de datos del MNIST contiene 60,000 imágenes de capacitación y 10,000 imágenes de prueba de dígitos escritos por estudiantes de secundaria y empleados de la Oficina del Censo de los Estados Unidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954dcda3-b799-4274-9eb9-f399932445a8",
   "metadata": {},
   "source": [
    "## Modelos de Clasificacion con Keras\n",
    "\n",
    "### **Objetivos de este Notebook**\n",
    "\n",
    "<h5> 1. Uso de la base de datos MNIST para entrenar varios sistemas de procesamiento de imágenes</h5>\n",
    "<h5> 2. Construya una red neuronal. </h5>\n",
    "<h5> 3. Entrene y pruebe la red. </h5>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc684ef6-55d6-4614-8193-42a6ea31a0a0",
   "metadata": {},
   "source": [
    "## Importar Keras y paquetes necesarios\n",
    "\n",
    "- Vamos a comenzar importando Keras y algunos de sus modulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44e62183-3235-430c-9777-a4bf23d43841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59109ad0-ef2f-4ba6-9745-de13d4c65d39",
   "metadata": {},
   "source": [
    "- Ya que estamos tratando con imágenes, también importemos la capa de scripting Matplotlib para ver las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28b85d5-152e-42e1-9754-43d54625d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75996a66-a45a-48e7-93b6-b9d7cf0984e1",
   "metadata": {},
   "source": [
    "- La biblioteca de Keras incluye convenientemente el conjunto de datos MNIST como parte de su API. \n",
    "\n",
    "- Entonces, carguemos el conjunto de datos MNIST de la biblioteca de Keras. El conjunto de datos se divide fácilmente en un conjunto de entrenamiento y un conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ead6ebe-fd9f-47b4-9ed5-19631373f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar los datos\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Leer los datos\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb459938-4dd0-4eec-9db3-efa8946914ec",
   "metadata": {},
   "source": [
    "- Confirmemos el número de imágenes en cada conjunto. Según la documentación del conjunto de datos, deberíamos tener 60000 imágenes en X_train y 10000 imágenes en X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab6d9ac-55d3-40fc-97ae-1069ac36ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e9a30-8a9b-4a87-a230-ec8a0c375789",
   "metadata": {},
   "source": [
    "- El primer número en la tupla de salida es el número de imágenes y los otros dos números son el tamaño de las imágenes en el conjunto de datos. Entonces, cada imagen tiene 28 píxeles por 28 píxeles.\n",
    "\n",
    "- Visualicemos la primera imagen del conjunto de entrenamiento utilizando la capa de secuencias de comandos de Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e34ffb3-99dd-4341-9146-1bb77efe00ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x120b6190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf18755-6c74-493e-bd32-bf43634ad04c",
   "metadata": {},
   "source": [
    "- Con las redes neuronales convencionales, no podemos alimentar la imagen como entrada tal como está. Así que necesitamos aplanar las imágenes en vectores unidimensionales, cada uno de tamaño 1 x (28 x 28) = 1 x 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bf3c10b-8534-4e50-a83c-7014f816a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplanar imagenes dentro de one-dimensaional vector\n",
    "\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2] \n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19162608-d8bf-4fb3-8328-d4999721b6be",
   "metadata": {},
   "source": [
    "- Dado que los valores de los píxeles pueden oscilar entre 0 y 255, normalicemos los vectores para que estén entre 0 y 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27162cb9-1790-493f-8a9e-a326a2c79821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff1f96a-14ea-4890-a490-e83bc5a09451",
   "metadata": {},
   "source": [
    "- Finalmente, antes de comenzar a construir nuestro modelo, recuerde que para la clasificación necesitamos dividir nuestra variable objetivo en categorías. Usamos la función to_categorical del paquete Keras Utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ee62fcf-bf46-43e3-9d79-fb8af6b39a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1266aac-9e64-4c5f-95d2-ce66032d5875",
   "metadata": {},
   "source": [
    "## Construir una Red Neuronal\n",
    "\n",
    "- Definimos una funcion para construir el modelo de Clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de18f04-30cf-4e6a-acff-38fdcc00b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classification model\n",
    "def classification_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, activation='relu', input_shape=(num_pixels,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e384fe7-1840-49fa-974f-a8bda64c8ffa",
   "metadata": {},
   "source": [
    "## Entrenar y evaluar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d69f7f-c6bb-42bb-8321-0c1b63561aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 72s - loss: 0.1855 - accuracy: 0.9441 - val_loss: 0.1036 - val_accuracy: 0.9670\n",
      "Epoch 2/10\n",
      "1875/1875 - 76s - loss: 0.0786 - accuracy: 0.9758 - val_loss: 0.0904 - val_accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "1875/1875 - 73s - loss: 0.0529 - accuracy: 0.9834 - val_loss: 0.0845 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "1875/1875 - 87s - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.0792 - val_accuracy: 0.9751\n",
      "Epoch 5/10\n",
      "1875/1875 - 82s - loss: 0.0316 - accuracy: 0.9897 - val_loss: 0.0808 - val_accuracy: 0.9785\n",
      "Epoch 6/10\n",
      "1875/1875 - 82s - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0851 - val_accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "1875/1875 - 81s - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0877 - val_accuracy: 0.9775\n",
      "Epoch 8/10\n",
      "1875/1875 - 87s - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.1163 - val_accuracy: 0.9741\n",
      "Epoch 9/10\n",
      "1875/1875 - 86s - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0987 - val_accuracy: 0.9780\n",
      "Epoch 10/10\n",
      "1875/1875 - 94s - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0927 - val_accuracy: 0.9816\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = classification_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5773c4ce-0488-4304-86f3-7bd9c76d60ed",
   "metadata": {},
   "source": [
    "- Visualizamos la precision y el correspondiente Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790ef170-7b96-4be7-b6cf-540ee05aefda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9815999865531921% \n",
      " Error: 0.01840001344680786\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {}% \\n Error: {}'.format(scores[1], 1 - scores[1]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa31e87-bd2a-478a-83dc-5e753c8786b5",
   "metadata": {},
   "source": [
    "- Ejecutar 10 épocas en realidad podría llevar más de 20 minutos. Pero disfrute de los resultados a medida que se generan.\n",
    "\n",
    "- A veces, no puede darse el lujo de volver a entrenar su modelo cada vez que quiera usarlo, especialmente si tiene limitados recursos computacionales y el entrenamiento de su modelo puede llevar mucho tiempo. Por lo tanto, con la biblioteca de Keras, puede guardar su modelo después del entrenamiento. Para hacer eso, usamos el método de guardar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7aaf96d-ed39-41bd-85cd-1bac8dc7542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classification_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ce3ea-7fb4-48e5-816b-e67abcc574a2",
   "metadata": {},
   "source": [
    "- Dado que nuestro modelo contiene matrices multidimensionales de datos, los modelos generalmente se guardan como archivos .h5.\n",
    "\n",
    "- Cuando esté listo para usar su modelo nuevamente, use la función **load_model** from **keras.models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5efbee-2d17-4d79-9244-8b6f3cf5750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf05bd1d-5e0f-4b34-9fa0-248662448648",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = load_model('classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57216513-d076-46ac-9b1e-dc585f873462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
